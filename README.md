# Projeto de Análise de Dados com Azure Databricks

Este projeto foi desenvolvido como parte dos meus estudos em **Azure** e **Databricks**, combinando o poder do Spark com a escalabilidade da nuvem da Microsoft. O objetivo foi criar um pipeline de análise de dados eficiente e escalável, ideal para ambientes corporativos que demandam performance, segurança e insights de negócio rápidos.

---

## Tecnologias Utilizadas

- **Azure Databricks**
- **Azure Data Lake Storage**
- **Apache Spark (PySpark)**
- **Azure Synapse (conector)**

---

## Objetivo do Projeto

Criar um fluxo completo de ingestão, tratamento, análise e visualização de dados utilizando o Databricks como motor principal. O cenário simulado é de uma empresa de e-commerce que deseja entender o comportamento de compra dos seus clientes.

---

## Pipeline de Dados

1. **Ingestão de dados brutos** do Data Lake (formato CSV).
2. **Tratamento com PySpark**: limpeza, transformação e enriquecimento.
3. **Criação de tabelas Delta** para otimização das consultas.
4. **Análise exploratória** com Spark SQL.
5. **Exportação para Power BI** via Azure Synapse.

---



## Aprendizados

- Configurar e gerenciar clusters no Azure Databricks.
- Trabalhar com arquivos grandes no formato Delta.
- Integração entre serviços do Azure.
- Aplicar boas práticas em notebooks colaborativos.
- Visualizar insights com dashboards dinâmicos.

---

## Próximos passos

- Automatizar a ingestão de dados com Azure Data Factory.
- Criar alertas com Azure Monitor para detecção de anomalias.
- Treinar um modelo de Machine Learning com MLFlow dentro do Databricks.

---

## Contribuindo

Esse repositório é um projeto pessoal, mas feedbacks, sugestões e colaborações são sempre bem-vindos!

---

## Autor

Jhonatan Pereira Costa  
